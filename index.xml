<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PSKim Blog</title>
    <link>https://pskim-b.github.io/</link>
    <description>Recent content on PSKim Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 20 Feb 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://pskim-b.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[ADsP]0.분석(준)전문가 자격증 공부해보자</title>
      <link>https://pskim-b.github.io/working/20210220_data_challenges_in_bigdata/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/working/20210220_data_challenges_in_bigdata/</guid>
      <description>😃
원본글 : https://luminousmen.com/post/data-challenges-in-big-data
내 친구가 나에게 흥미로운 질문을 했다. 데이터 관리 전문가로 의미있는 기술이 무엇이며 그것을 발전시키는 방법은 무엇인지. 사실 이러한 질문은 나에게 많은 생각을 하게 했는데 아직 명확한 그림이 그려져있지 않기 때문이다. 따라서 데이터 관리에 대한 현재의 상태와 미래를 고민해보기로 했다.
 아래 이야기 할 각 데이터 레이어들은 데이터 영역의 문제를 해결하기 위한 특정한 형태를 가진다. 빅데이터가 있는 곳에는 큰 문제들이 존재하기 때문이다(&amp;hellip;)
특정 레이어에서 데이터를 처리할 때에는 그를 위한 특별한 스킬들이 필요로 한다.</description>
    </item>
    
    <item>
      <title>[ADsP]5.R 데이터 프레임 활용 </title>
      <link>https://pskim-b.github.io/posts/adsp/5_r_data_frame/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/adsp/5_r_data_frame/</guid>
      <description>😃
데이터 프레임의 데이터를 행/열 단위로 추출/제거/수정 함으로써 데이터 분석을 위한 데이터 클랜징 작업을 수행할 수 있다. 많은 경우 미리 데이터가 클랜징되어 들어오지만, 만약 R을 통해서 데이터를 수정해야 하는 경우 데이터 프레임을 사용하면 좋다.
 데이터 프레임 생성 # 벡터를 통한 생성  &amp;gt; v1=c(1,2,3,4) &amp;gt; v2=c(&amp;#34;a&amp;#34;,&amp;#34;b&amp;#34;,&amp;#34;c&amp;#34;,&amp;#34;d&amp;#34;) &amp;gt; v3=c(T,F,F,T) &amp;gt; data.frame(v1,v2,v3) v1 v2 v3 1 1 a TRUE 2 2 b FALSE 3 3 c FALSE 4 4 d TRUE # 행렬을 통한 생성  &amp;gt; m1 = matrix(c(1,3,5,7,9,2,4,6,8,19,2,3,5,7,11),ncol=3) &amp;gt; as.</description>
    </item>
    
    <item>
      <title>[HBase] 최적화 튜닝 가이드 (cloudera 가이드)</title>
      <link>https://pskim-b.github.io/working/20210215_hbase_opt/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/working/20210215_hbase_opt/</guid>
      <description>😃
HBase에 대한 최적화 설정을 찾아보던 중 Hortonworks시절에 HBase 최적화와 관련된 블로그가 있어서 정리하여보려고 한다. 넓은 부분에 대해서 이야기하고 있는 일반적인 가이드이기 때문에, 모든 환경에 적합한 설정은 아닐 수 있으나 이 내용은 참조한다면 해답을 찾을 수 있을 것이라 생각한다.
 1. HBase Master HeapSize  권장값 : 4GB - 8GB (region 개수에 따라) 설명 : HBase Master는 read/write 작업에 직접적으로 영향을 끼치지 않기 때문에 크게 할당할 필요가 없다. 대신 region/table의 상태를 계속해서 메모리에 올려놓고 있기 때문에 그 수가 늘어나는 것과 비례하여 증가시켜야 한다.</description>
    </item>
    
    <item>
      <title>[ADsP]4.R 데이터 구조 ( vector , list, dataframe )</title>
      <link>https://pskim-b.github.io/posts/adsp/4_r_data_structure/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/adsp/4_r_data_structure/</guid>
      <description>😃
R에서 간단히 파일을 입출력하는 방법을 알아보았다. 이제 그 데이터를 가지고 분석하기 위해서 내부적으로 R의 데이터 구조로 저장해야 한다. R에는 크게 벡터(vector), 리스트(list), 행렬(matrix), 배열(Arrays), 요인(Factors), 데이터프레임(Dataframe), 스칼라(scala) 로 나눌 수 있다.
 R 데이터 구조 1. 스칼라(scala) 단일 값을 갖는 자료구조로 프로그램 내에서 원소가 하나인 벡터처럼 인식된다. logical, integer, double, complex, character 와 같은 데이터 뿐만 아니라 NULL, NA(Not Available)도 포함한 모든 단일 값을 이야기한다.
&amp;gt; pi [1] 3.141593 &amp;gt; mode(pi) [1] &amp;#34;numaric&amp;#34; 2.</description>
    </item>
    
    <item>
      <title>[ADsP]3.R 데이터 처리/분석</title>
      <link>https://pskim-b.github.io/posts/adsp/3_r_data_processing/</link>
      <pubDate>Sun, 31 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/adsp/3_r_data_processing/</guid>
      <description>😃
지난 글에서 간단하게 R의 기본언어를 알아보았다. 이번 글에서는 실제로 R을 사용하여 데이터를 입출력하는 방법을 알아보려고 한다.
 데이터 처리/분석 과정 모든 일이 그러하듯이 데이터 분석을 시작할 때에도 그것의 목적을 명확히 하고 이에 맞는 분석 방법론을 선택해야 한다. 정확한 분석을 위해서는 분석가가 설계한대로 올바른 데이터가 입력되어야 한다. 따라서 데이터를 분석이 가능한 형태로 전처리하는 과정이 필요하며 이를 데이터 핸들링이라고도 한다. 그리고 데이터 분석 이후에 의사결정권자와 고객에 보고서 형태로 제공됨으로써 분석과제가 종료된다.</description>
    </item>
    
    <item>
      <title>[ADsP]2.R 프로그램 기초</title>
      <link>https://pskim-b.github.io/posts/adsp/2_r_programming/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/adsp/2_r_programming/</guid>
      <description>😃
요즘의 대세는 python이야!! 라고 많은 이들이 외치지만 전통적인 분석 언어 R도 많이 사용된다. 분석가에 따라서 R을 쓰기도하고 python을 쓰기도 해서, 많은 프로젝트들에서 R과 python 모두를 만족하는 환경을 제공하고 있다(일반적으로는 sparkR/pySpark로 분산환경에서 학습/분석작업을 수행하고 있다). 이번 장에는 간단히 R로 분석을 하기 위한 간단한 문법을 알아보자!!
 R소개 R은 오픈소스 프로그램으로 통계 및 데이터마이닝과 그 결과를 그래프를 위한 언어이다. 오픈소스이기 때문에 지속적으로 최신의 통계분석과 데이터 마이닝 기술이 반영되어 발전되고 있다. 새로운 것을 이해하는데 가장 좋은 방법 중 하나는 기존에 친숙한 도구들과 비교하는 것이다.</description>
    </item>
    
    <item>
      <title>[ADsP]0.분석(준)전문가 자격증 공부해보자</title>
      <link>https://pskim-b.github.io/posts/adsp/0_start/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/adsp/0_start/</guid>
      <description>😃
빅데이터를 처리하는 솔루션을 개발하고 구축하는게 나의 주된 업무이지만, 기술에 대한 호기심이 많은터라 새로운 분야를 접할 때마다 조금조금씩 공부하고는 한다. AI/분석업무도 나에게는 그런 영역 중 하나인데, 대학교때 공통교양이였던 통계학을 멀리해서 벌을 받는 것인지 몰라도 기억속에 그리 오래 남지 않았다.
그래서 알아두면 나쁘지 않을 생각을 하고 있는 중에 요즘 데이터 관련 직종으로 취업하는 대학생이라면 하나씩 다 가지고 있다던 데이터분석 준전문가(ADsP) 자격증을 따보기로 결심했다. 자격증 자체는 &amp;lsquo;정보처리기사&amp;rsquo; 같이 크게 의미없는 한줄이 될 수 있겠다만, 그냥 재미있을 것 같으니까 해보기로 한다.</description>
    </item>
    
    <item>
      <title>[ADsP]1.통계분석의 시작</title>
      <link>https://pskim-b.github.io/posts/adsp/1_statistical_analysis/</link>
      <pubDate>Mon, 25 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/adsp/1_statistical_analysis/</guid>
      <description>😃
이상한 순서이지만, 3장의 &amp;lsquo;데이터 분석&amp;rsquo; 을 먼저 보려고 한다. 그 이유는 1장의 &amp;lsquo;데이터의 이해&amp;rsquo; 부터 보게된다면 뒤로 갈 수록 쳐질것 같은 기분이 들어서이다. 두렵고 어려울 것이라 생각되는 부분을 가장 먼저 부수고 들어가보자!!
 내용 일반적으로 데이터를 처리할 때 legacy시스템에서 직접 데이터를 가져오기도 하지만 ODS(Operational Data Store) 에서 데이터를 가져오는 것을 권고한다. 그 이유는 운영 중에 legacy시스템에서 데이터를 직접 가져오는 것은 legacy시스템에 부하를 유발함으로 운영 서비스에 영향을 끼칠 수 있기 때문이다.</description>
    </item>
    
    <item>
      <title>Windows10 Git &#39;OpenSSH Key is invalid&#39; 오류 </title>
      <link>https://pskim-b.github.io/posts/etc/20210122_git_win10_auth/</link>
      <pubDate>Fri, 22 Jan 2021 22:42:30 +0900</pubDate>
      
      <guid>https://pskim-b.github.io/posts/etc/20210122_git_win10_auth/</guid>
      <description>Windows10 환경에서 생성한 rsa key가 Github account/repository에 SSH키를 등록이 안되는 경우가 있다.
다른 블로그 및 stackoverflow에서도 아래와 같이 rsa key 생성을 가이드 하고 있다.
PS&amp;gt; ssh-keygen -b 2048 -t rsa 너무 간단한 작업이여서 다를 게 없을 것 같은데 안되서 굉장히 당황스러웠다.
위와 같은 명령어로 생성된 ~/.ssh/id_rsa.pub 파일의 내용을 github에 등록하면 &amp;lsquo;Key is invalid. You must supply a key in OpenSSH public key format&amp;rsquo; 와 같은 에러메세지가 나온다.
왜 이상한 포맷으로 생성되는지 잘 모르겠으나, 이러한 경우 아래와 같이 rsa 대신 ed25519를 생성하여 id_25519.</description>
    </item>
    
    <item>
      <title>[HIVE] 파티션 타입 및 종류</title>
      <link>https://pskim-b.github.io/posts/hive/hive_partition_type/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pskim-b.github.io/posts/hive/hive_partition_type/</guid>
      <description>😃
Hive 파티션(partition)의 개념은 RDBMS 와 크게 다르지 않다. 테이블을 하나 이상의 키로 파티셔닝(partitioning) 할 수 있다. 기본적으로 테이블 생성 시 DDL문을 통해 파티션키 유무를 정할 수 있지만, row가 많은 Fact 테이블 같은 경우는 선택이 아닌 필수이다. 데이터를 조회 할 때 파티션 키 값을 잘 구성해야 hive 내부적으로 skip-scan이 발생하여 불필요한 I/O를 최소화 할 수 있다. 또한 파티션 키의 순서에 따라 hdfs 상의 디렉토리 구조가 결정됨으로 워크로드에 따라 그 순서도 적절히 결정해야 한다.</description>
    </item>
    
  </channel>
</rss>
